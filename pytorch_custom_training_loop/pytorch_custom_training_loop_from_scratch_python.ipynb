{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3148dbf",
   "metadata": {},
   "source": [
    "# **PyTorch training script from scratch**\n",
    "\n",
    "We'll use a simple example: **binary classification** on a synthetic dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Problem Setup\n",
    "\n",
    "Let’s assume a toy dataset where we classify points in 2D as class 0 or 1 based on a simple linear boundary.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Imports & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5615a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb28ddd",
   "metadata": {},
   "source": [
    "## 2. Sample Dataset\n",
    "\n",
    "We generate 2D points and classify them using a line `x + y > 1` → class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ce6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Generate 1000 2D points\n",
    "X = np.random.rand(1000, 2)\n",
    "y = (X[:, 0] + X[:, 1] > 1).astype(np.float32)  # label: 1 if x + y > 1\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5c3de1",
   "metadata": {},
   "source": [
    "## 3. Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a260ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # shape: (N, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c3261",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "* `__init__`: Converts `numpy` arrays to `torch.tensor`.\n",
    "* `__len__`: Returns dataset length.\n",
    "* `__getitem__`: Gets a sample (X, y) pair.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Model Architecture\n",
    "\n",
    "Let’s build a small fully connected neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6219bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 16)      # Input: 2 features\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 1)      # Output: 1 logit for binary class\n",
    "        self.sigmoid = nn.Sigmoid()      # Optional for inference\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d92c73",
   "metadata": {},
   "source": [
    "## 5. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d793f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae31ae",
   "metadata": {},
   "source": [
    "## 6. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b3439",
   "metadata": {},
   "source": [
    "## 7. Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734aa40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleClassifier()\n",
    "criterion = nn.BCEWithLogitsLoss()  # Better for numerical stability\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd547996",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1cfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        # ---- Forward Pass ----\n",
    "        logits = model(batch_X)\n",
    "        loss = criterion(logits, batch_y)\n",
    "\n",
    "        # ---- Backward Pass ----\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59205615",
   "metadata": {},
   "source": [
    "## 9. Evaluation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits = model(torch.tensor(X, dtype=torch.float32))\n",
    "    predictions = (torch.sigmoid(test_logits) > 0.5).float()\n",
    "    acc = (predictions.squeeze() == torch.tensor(y)).float().mean()\n",
    "    print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5632f",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "\n",
    "### Summary of Each Component:\n",
    "\n",
    "| Component          | Purpose                                          |\n",
    "| ------------------ | ------------------------------------------------ |\n",
    "| **Dataset class**  | Wraps custom numpy arrays into a PyTorch dataset |\n",
    "| **Dataloader**     | Feeds mini-batches into the model                |\n",
    "| **Model**          | A basic 2-layer neural network                   |\n",
    "| **Forward pass**   | Compute outputs from inputs                      |\n",
    "| **Loss**           | Binary Cross Entropy with logits                 |\n",
    "| **Backward pass**  | Compute gradients using `loss.backward()`        |\n",
    "| **Optimizer step** | Updates weights via `optimizer.step()`           |\n",
    "| **Epoch loop**     | Repeats training multiple times over data        |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
