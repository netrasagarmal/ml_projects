{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4996249b",
   "metadata": {},
   "source": [
    "### Start by importing some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9ad041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0d3b13",
   "metadata": {},
   "source": [
    "### Step 1: **Understanding the Goal**\n",
    "\n",
    "We want to learn a **linear relationship** between input (`x`) and output (`y`):\n",
    "\n",
    "$$\n",
    "\\text{Prediction: } \\hat{y} = m \\cdot x + b\n",
    "$$\n",
    "\n",
    "Our **goal** is to find the best values for:\n",
    "\n",
    "* `m` (slope)\n",
    "* `b` (intercept)\n",
    "\n",
    "So that predictions (`ùë¶ÃÇ`) are **as close as possible** to the actual values `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6d582",
   "metadata": {},
   "source": [
    "For this example well consider a sample dataset that we'll create by random function where we will predict test score based on number of study hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567bae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1, 2, 3, 4, 5]        \n",
    "x = [random.choice(lst) for _ in range(100)]        # Hours of study\n",
    "y = [random.randint(25,100) for _ in range(100)]    # Test scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f031a",
   "metadata": {},
   "source": [
    "### Step 2: **Start with Random Initialization**\n",
    "\n",
    "We start by setting `m = 0` and `b = 0`. At this point, our model has **no knowledge**, so predictions will be poor.\n",
    "\n",
    "**Why?**\n",
    "\n",
    "* This is a **common practice** in training models. You start with a guess, then improve using data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c91d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "m = 0.0  # slope\n",
    "b = 0.0  # intercept\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "n = len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de4e90",
   "metadata": {},
   "source": [
    "### Step 3: **Measure How Bad the Predictions Are (Loss Function)**\n",
    "\n",
    "We need a way to measure **how far off** our predictions are from the actual values.\n",
    "\n",
    "We use **Mean Squared Error (MSE)**:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $y_i$ is the actual value\n",
    "* $\\hat{y}_i = m x_i + b$ is the predicted value\n",
    "\n",
    "```\n",
    "y_pred = [m * xi + b for xi in x]\n",
    "error = [y[i] - y_pred[i] for i in range(n)]\n",
    "```\n",
    "\n",
    "**Why MSE?**\n",
    "\n",
    "* It penalizes **large errors** more than small ones (because of squaring)\n",
    "* It is smooth and differentiable (important for gradient descent)\n",
    "* It has a clear geometric meaning: the average squared vertical distance from points to the line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d904f",
   "metadata": {},
   "source": [
    "### Step 4: **Use Gradient Descent to Improve**\n",
    "\n",
    "Now that we can measure the error, we want to **reduce it**.\n",
    "\n",
    "**Gradient Descent** is an algorithm that:\n",
    "\n",
    "* Measures the **slope of the loss** with respect to the model parameters\n",
    "* Updates the parameters to **reduce the loss**\n",
    "\n",
    "We take the **partial derivatives** of the loss with respect to `m` and `b`.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: **Derive the Gradients**\n",
    "\n",
    "#### Gradient with respect to `m`:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial m} = -\\frac{2}{n} \\sum x_i (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "#### Gradient with respect to `b`:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial b} = -\\frac{2}{n} \\sum (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "These tell us **how to change** `m` and `b` to **decrease the loss**.\n",
    "\n",
    "```\n",
    "dm = (-2/n) * sum([x[i] * error[i] for i in range(n)])\n",
    "db = (-2/n) * sum(error)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9b41a",
   "metadata": {},
   "source": [
    "### Step 6: **Update Parameters**\n",
    "\n",
    "We update `m` and `b` using a small step in the opposite direction of the gradient:\n",
    "\n",
    "$$\n",
    "m = m - \\alpha \\cdot \\frac{\\partial \\text{MSE}}{\\partial m}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = b - \\alpha \\cdot \\frac{\\partial \\text{MSE}}{\\partial b}\n",
    "$$\n",
    "\n",
    "Where `Œ±` (alpha) is the **learning rate** ‚Äì a small constant like `0.01`.\n",
    "\n",
    "**Why learning rate?**\n",
    "\n",
    "* Controls how big each update is\n",
    "* Too large: might overshoot the minimum\n",
    "* Too small: slow learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacab4b",
   "metadata": {},
   "source": [
    "### Step 7: **Repeat for Many Epochs**\n",
    "\n",
    "```\n",
    "epochs = 1000\n",
    "```\n",
    "\n",
    "We keep repeating:\n",
    "\n",
    "1. Predict\n",
    "2. Calculate loss (MSE)\n",
    "3. Calculate gradients\n",
    "4. Update `m` and `b`\n",
    "\n",
    "After many iterations, the model gradually **learns better parameters**, and the loss decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147c195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss=5261.0400, m=4.3022, b=1.3808\n",
      "\n",
      "Final model: y = 15.62x + 6.53\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    # Get the predicted value with current values of m and b, then calculate the error using MSE\n",
    "    # y_pred = mx + b\n",
    "    y_pred = [m * xi + b for xi in x]\n",
    "    error = [y[i] - y_pred[i] for i in range(n)]\n",
    "    \n",
    "    # Compute gradients\n",
    "    dm = (-2/n) * sum([x[i] * error[i] for i in range(n)])\n",
    "    db = (-2/n) * sum(error)\n",
    "    \n",
    "    # Update parameters\n",
    "    m -= learning_rate * dm\n",
    "    b -= learning_rate * db\n",
    "\n",
    "    # Optionally print loss every 100 iterations\n",
    "    if epoch % 100 == 0:\n",
    "        loss = sum([(y[i] - y_pred[i]) ** 2 for i in range(n)]) / n\n",
    "        print(f\"Epoch {epoch}: Loss={loss:.4f}, m={m:.4f}, b={b:.4f}\")\n",
    "\n",
    "print(f\"\\nFinal model: y = {m:.2f}x + {b:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af9006",
   "metadata": {},
   "source": [
    "### Final Step: **Converge to Best Line**\n",
    "\n",
    "Eventually, the model will converge (or stop improving significantly). At this point:\n",
    "\n",
    "* You have `m` and `b` that define the best-fit line\n",
    "* You can now **predict y for any x**\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Steps\n",
    "\n",
    "| Step | What Happens                            | Why It Matters                            |\n",
    "| ---- | --------------------------------------- | ----------------------------------------- |\n",
    "| 1    | Initialize `m=0`, `b=0`                 | Start with a baseline                     |\n",
    "| 2    | Make predictions `yÃÇ = mx + b`          | Compute model output                      |\n",
    "| 3    | Calculate MSE loss                      | Measure how bad predictions are           |\n",
    "| 4    | Compute gradients (‚àÇMSE/‚àÇm and ‚àÇMSE/‚àÇb) | Find how to change weights to reduce loss |\n",
    "| 5    | Update `m` and `b` using gradients      | Learn better values                       |\n",
    "| 6    | Repeat many times                       | Gradually converge to optimal solution    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55128b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1, 2, 3, 4, 5]        \n",
    "x_test = [random.choice(lst) for _ in range(10)]        # Hours of study\n",
    "y_test_actual = [random.randint(25,100) for _ in range(10)]    # Ground truth (made-up for this example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca5b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the learned model\n",
    "y_test_pred = [round(m * xi + b,3) for xi in x_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7363d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE on test data\n",
    "mse_test = sum([(y_test_actual[i] - y_test_pred[i])**2 for i in range(len(x_test))]) / len(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a5379f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST RESULTS ---\n",
      "Final learned model: y = 15.62x + 6.53\n",
      "Test Predictions: [53.407, 69.032, 22.158, 53.407, 22.158, 37.782, 69.032, 22.158, 53.407, 37.782]\n",
      "Actual Values:    [96, 63, 29, 30, 47, 37, 30, 44, 60, 80]\n",
      "Test MSE: 688.9383\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- TEST RESULTS ---\")\n",
    "print(f\"Final learned model: y = {m:.2f}x + {b:.2f}\")\n",
    "print(\"Test Predictions:\", y_test_pred)\n",
    "print(\"Actual Values:   \", y_test_actual)\n",
    "print(f\"Test MSE: {mse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f185f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
